{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArthiUsaha Tiering Model Training\n",
    "\n",
    "This notebook trains and evaluates 5 classification algorithms to predict the partner Tier (Bronze, Silver, Gold) based on financial behavior features.\n",
    "\n",
    "## Algorithms:\n",
    "1. Logistic Regression\n",
    "2. Random Forest Classifier\n",
    "3. Support Vector Machine (SVM)\n",
    "4. Gradient Boosting Classifier\n",
    "5. K-Nearest Neighbors (KNN)\n",
    "\n",
    "## Pipeline:\n",
    "- Data Loading\n",
    "- Preprocessing (Scaling, Encoding)\n",
    "- Model Training\n",
    "- Evaluation (Precision, Recall, F1-Score, Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset generated by generate_ml_data.py\n",
    "DATA_PATH = '../HACKATHON_2025_DATA/training_data.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Data Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "sns.countplot(x='tier', data=df)\n",
    "plt.title('Tier Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(df['tier'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features and Target\n",
    "features = ['total_principal', 'total_outstanding', 'max_dpd', 'repayment_rate', 'bill_count', 'total_bill_amount', 'total_paid_amount']\n",
    "target = 'tier'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Encode Target (Bronze=0, Silver=1, Gold=2 or similar)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Test Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Functions for Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(classifier):\n",
    "    \"\"\"\n",
    "    Creates a pipeline with preprocessing (Scaling) and the given classifier.\n",
    "    \"\"\"\n",
    "    # Numerical Preprocessing: Impute missing (just in case) + Scale\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, features)\n",
    "        ])\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def evaluate_model(name, pipeline, X_test, y_test, le):\n",
    "    \"\"\"\n",
    "    Evaluates the model and returns a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"--- {name} Results ---\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 Score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Classifiers\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through models\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    pipeline = create_pipeline(clf)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    metrics = evaluate_model(name, pipeline, X_test, y_test, le)\n",
    "    results.append(metrics)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(by='F1 Score', ascending=False, inplace=True)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# Plot Comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='F1 Score', y='Model', data=results_df, palette='viridis')\n",
    "plt.title('Model Comparison (F1 Score)')\n",
    "plt.xlim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Best Model\n",
    "We will save the best performing model for use in the `ml_engine` service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Identify best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# Retrain best model on full data (optional, or just use the trained one)\n",
    "best_clf = classifiers[best_model_name]\n",
    "best_pipeline = create_pipeline(best_clf)\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save Model and Label Encoder\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_pipeline, f)\n",
    "    \n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Model and Label Encoder saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
